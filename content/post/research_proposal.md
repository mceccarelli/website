---
title: "Research_proposal"
date: 2022-05-17T01:49:34-04:00
draft: false
---

### Background

Throughout my time in 580, working through the various assignments and such, I learned a lot about research in the field of computer science.  I was introduced to the "literature" for the first time, and it has been by far my best resource for learning and discovering new topics throughout computer science.  Furthermore, my meetings with Professor Kapfhammer and Professor OBC taught me lots as well, they are well-versed in the literature and helped guide me through.  As it turns out, there's so much more out there that I was completely unaware of, areas and ideas that go far beyond the scope of any course.

It was very hard to choose a topic at the end of the day, and if I could pick more than one I certainly would.  However, there's obviously only one senior project that I'll be doing, and it has been my goal for a long time to ensure that I am really interested in my topic.  I don't want to ever dread working, since there will be a lot of it, and I'd rather be engaged and passionate about my creation.  Moreover, as most of the professors here know by now, I have a keen interest in mathematics, my other major.  I will be doing a split comp (two separate ones), as advised by the mathematics department, since I will be using that one to dive deep into higher concepts, with the goal of showing graduate programs that I am capable of research in the field.  That gave me a few more options for my computer science project, though I still wanted math to be a part of it in some way.

Thus, I was lead in the direction of cryptography, a subject I've loved for some time.  I've always thought the algorithms which leverage "impossible" problems in mathematics were absolutely incredible, and the fact that they have a very prevalent and practical application is beautiful.  I've studied various cryptosystems over the years, ever since taking the cryptography course, but I've neglected a huge area of the field -- hashing algorithms.

### Hashing Algorithms

Hashing algorithms are one way functions, designed to take any input and deliver an indecipherable output.  They leverage several of the ideas found in various cryptosystems, and research has been going on in the field for decades.  The literature is ripe with all different subtopics found in cryptography, though some of it is quite difficult to parse through, as I still have very limited knowledge of hash functions in general.  However, they combine my two passions, mathematics and computer science, and designing my senior project around them would be awesome.

I spent the entirety of 580 thinking about what I could do that would allow me to explore hashes while remaining feasible, and along the way I came up with tons of different ideas.  The first was to try and crack them, obviously, because that's tons of fun and super cool.  However, that quickly devolved into the "infeasible" project ideas bin, since tools that actually do this, such as `Hashcat` and `John the Ripper` have been years-long research projects designed to do the impossible, crack hashes.  Contributing to one of those repositories is still one of my goals, but that would not serve as my senior project in computer science, as it's very unlikely that I couldn't get it done in time.  There would simply be far too much to learn and do, and I am not at that level yet.

Next, I explored the idea of potentially designing my own hashing algorithm, or at least making a tool that showed the user all the steps in creating the hash for their input.  This was certainly more feasible, but it was hard to identify a research "gap" with questions that I could answer through experimentation.  I picked up a couple of books to learn more about hash functions, and the prototype I designed for class was some of the implementation for the algorithms I read about.  However, I fell out of love for the idea, and with it hard to ask questions about it, other than me just teaching users about the hash functions, I decided to scrap it.

Finally, after a productive and insightful conversation with Professor OBC at the end of class one day, I had a plan lined up to experiment with entropy.  We discussed several possible ideas that I could work with, all dealing with the "randomness" of the hash algorithms' output.  This was super fun to read more about, and it left me with a lot of questions I was looking forward to researching:  Which hashing algorithms are the "most random"?  Does the input size or type matter?  Which functions lack randomness?  How do they all compare?  Those are all questions I can actually provide an answer to after performing some experimentation with a tool I build.  Plus, that's a super important part of hash functions and security in general, as randomness, or an increase in entropy, usually equates to stronger protection.  They're all appropriate questions to ask, and with the right mathematical models, I can provide solid answers with concrete evidence.

### Project Idea

During the assignment in which we were asked to design an experiment and find a few answers, even watered down ones, I started thinking about how much potential there was in this idea.  I built a tool, though not nearly as powerful as I have in mind for the future, that sufficed for the activity.  It took in a few hashes, and outputted the character counts of each one, in a way that they could be compared.  Admittedly, it wasn't a pretty output, I only used one hashing function, and the inputs were limited in scope, size, and type.  However, I was pleased to see that even with my limited amount of data, it was clear that SHA-256 does give "random" output, as all the possible characters usually appear in similar amounts.

In the future (for the senior project), I plan on improving every aspect of the prototype I built.  It should be able to accept input of any kind, or generate/retrieve input on its own.  The hashing algorithms used should vary, rather than being just limited to one, and the inputs should be hashed automatically, not having to be run through an algorithm and then submitted to the tool.  Also, actual mathematical models should be used for the analysis, not just me comparing numbers by looking at them.  I hope to have far too much data to be able to just "eyeball" it, so statistical models will need to be used, and it makes the results of the experiment way more robust.  Lastly, but of equal importance, the way the information is presented needs to be greatly improved.  The output, in its current state, is limited to a table I generated in the terminal window, but there are so many other tools out there (all of which will be named later) that make visualization of data easy to program.  The combination of all these things could lead to a really interesting software tool and a complete senior project that I'm not only proud of but can learn something from.

### Literature and Tools

Ever since I discovered Google Scholar, I've been obsessed with just how much free information there is out there.  There's obviously papers on just about anything, but to my surprise, there seems to be multiple on just about every topic in hashing algorithms.  Some of them are famous pieces of research that had enormous consequences in the field, and others are designed as a teaching tool to help explain hashing functions to individuals interested in learning.  I read through several of these papers, even though some of them were certainly beyond the scope of what I currently know, and they gave me a great view of where the current research is in the field, and how I can potentially contribute.  I feel the project I have proposed above is a great fit, as it answers interesting questions while remaining feasible for an undergraduate researcher to complete within a school year.

That said, it wouldn't be without some of the tools that are already readily available to me, which will play key roles in helping me achieve my goals for the project.  For example, there are some graphing programs, which will help me in visualizing and presenting the data I collect, already available for use, so I don't have to build them myself next year.  I can feed my data into these various programs and receive a graph or chart that is readable and clear.  For example, one I have been practicing using is `Bokeh`, an interactive Python graphing tool.  Another is `Streamlit`, a piece of software that has been used by several students in the past at Allegheny for various projects.  The plan is to use these tools to give myself a "head start" in the visualization part of the project, so I can focus more on the analysis.

Throughout the summer, my main goal is to read as much literature as I can and experiment with as many different tools as I can.  There's so much out there that I haven't even gotten to look at yet, and I strongly feel that reading more of the research that is already out there can only help me narrow my project idea and help me complete it.  Plus, perhaps the extra readings inspire me to tweak my idea, or even change my project entirely, and it's best to have an ironed out plan now rather than later.

### Ethical Concerns

One very important aspect of the program is the data, and even more so, how that data is implemented and used.  There are a lot of ethical concerns that surround the retrieval of data, so I will have to be very careful to ethically source any data that I am going to experiment with.  It is possible for me to generate all the data I feed into the hashing algorithms, such as files or sentences, but I would like to use real-life examples if I can, rather than just random words or characters I put together.  The data analytics course covers these ideas, but I haven't taken it yet, so any problems I come up with I'll have to ask about.

### Other Ideas

This report would not be complete without me acknowledging the potential for change, since I have already gone through several iterations of what I want to do, and it wouldn't surprise me if I end up changing things again.  As I mention above, I hope to use the time over the summer to dive into the literature even deeper, since I'm a big believer in reading, and the more knowledge I can gather the better my project and my idea in general is going to be.  I spent the entirety of 580 working my way through hashing algorithms, considering what I might do for my project, amending my plan several times.  However, after we picked advisors, I've had several productive meetings with Professor Kapfhammer, and he has showed another area of computer science that I am certainly developing a taste for.

The topic is testing, specifically certain kinds of tests that get labeled "flaky".  Flaky tests are tests that can both pass and fail on separate runs, despite there being no change to the code whatsoever.  They are a rich area in current research in computer science, and Professor Kapfhammer has published papers himself in the past on the subject.  I am super new to the area, which is why I'm so keen on reading a bunch over the summer, but the basic idea is this: find a way to combine automatic fault localization with flaky tests to create a tool that builds off ones that already exist but don't work well in certain situations.  Together, we looked at a couple papers that deal with the issue, and looked at a couple of tools that resolve some of the problems developers face with flaky tests.  However, there were some instances where the tools didn't work the best, and Professor Kapfhammer wrote a paper on some of those areas.  My goal would be to build a tool that leverages the ones that are already there, but improves upon them by strengthening them for situations where they are currently weak.

It's definitely feasible, and it sounds like an awesome project, one where I could really "save the day" by improving upon tools that are already being used frequently.  I plan on quite some time, as stated before, exploring the field of testing, specifically flaky tests.  By the beginning of the fall semester, I should have a much better idea of exactly what I want to do, so I can hit the ground running right away.
